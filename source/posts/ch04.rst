======
第四章 
======

在开始这一章之前，你可能需要补习一下数学知识。

另外，建议先通读一下 `Scrapy 中文文档 <http://scrapy-chs.readthedocs.org/zh_CN/0.22/intro/overview.html>`_ ，这样你会省去好多Google的时间。

**在收集数据的时候，有时我想不出来要这些数据能统计出什么，直到我背后中了一箭，哦不，直到对象说租房要挑个性价比高地理位置又好的地方后，我才明白大量数据的重要性。**

4.1 数据收集
-------------

简单抓取
~~~~~~~~

动手写一个最简单的爬虫
***********************

实际使用时遇到的问题
*********************

分布式抓取
~~~~~~~~~~~

scrapyd
*********

scrapy-redis
*************

4.2 爬虫示例
-------------

58同城
~~~~~~~

我简单写了一个 `收集58同城中上海出租房信息的爬虫 <https://github.com/lofyer/myspiders/tree/master/tongcheng>`_ ，包括的条目有： *描述* 、 *位置* 、 *价格* 、 *房间数* 、 *URL* 。

由于这些信息都可以在地图上表示出来，那我除了画统计图以外还会画它们在地图上的表示。

知乎
~~~~

http://blog.javachen.com/2014/06/08/using-scrapy-to-cralw-zhihu/

新浪微博
~~~~~~~~

1. 使用第三方SDK：

4.3 机器学习常用分类算法及Python实现
-------------------------------------

K邻近算法
~~~~~~~~~~

决策树
~~~~~~~~~~

朴素贝叶斯
~~~~~~~~~~

Logistic和Sigmoid回归
~~~~~~~~~~~~~~~~~~~~~

SVM
~~~~

AdaBoost
~~~~~~~~

4.4 无监督学习
---------------

4.5 数据可视化
---------------

数据统计
~~~~~~~~

Gephi

GraphViz

python-matplotlib

地理位置表示
~~~~~~~~~~~~

`百度地图API <http://developer.baidu.com/map/index.php?title=%E9%A6%96%E9%A1%B5>`_

`MaxMind GeoIP <http://dev.maxmind.com/geoip/geoip2/geolite2/>`_
